{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8B2lNXVQJ64"
      },
      "source": [
        "# Лабораторная работа 7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZYHCxCGQJ66"
      },
      "source": [
        "## 1. Начальные условия"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnMub2LYQJ67"
      },
      "source": [
        "### a. Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGC2LtTPQJ67"
      },
      "source": [
        "В рамках проекта был использован датасет [leaf flower fruit annotation](https://www.kaggle.com/datasets/ar5entum/leaf-flower-fruit-annotation), предназначенный для задачи сегментации растений на изображениях. Данная задача имеет широкие практические применения в различных отраслях. К примеру, технологии автоматического выделения и классификации растительных объектов могут востребованы в агротехнике (мониторинг состояния посевов, диагностика заболеваний растений), экологическом мониторинге, ботанических исследованиях и в разработке приложений для автоматического определения видов растений по фотографии."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "45z4-5k8Qvfl",
        "outputId": "bb4e4003-a4e2-4d9d-dea4-8d3814cb1de8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c13b9658-b160-4da2-96d4-06cd822a4577\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c13b9658-b160-4da2-96d4-06cd822a4577\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tM0w6MN9QJ67",
        "outputId": "5be90c9d-8476-41ab-e64e-f384356f42cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2025.4.26)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.4.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle) (5.29.4)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.4.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle) (0.5.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle\n",
        "!pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxRK8KWHQJ68",
        "outputId": "75d3f5c0-1738-438b-bf05-29f6df45d614"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/ar5entum/leaf-flower-fruit-annotation\n",
            "License(s): unknown\n",
            "Downloading leaf-flower-fruit-annotation.zip to data7\n",
            "  0% 0.00/20.2M [00:00<?, ?B/s]\n",
            "100% 20.2M/20.2M [00:00<00:00, 1.27GB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d ar5entum/leaf-flower-fruit-annotation -p data7 --unzip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxlcURULQJ68",
        "outputId": "68ec73b7-1044-4407-f1fd-ca79dab4174d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.11/dist-packages (2.0.8)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pycocotools) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pycocotools) (2.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pycocotools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pyLjvPzQJ69",
        "outputId": "75828f2f-0d18-4297-fd4f-95828099ecbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting segmentation_models_pytorch\n",
            "  Downloading segmentation_models_pytorch-0.5.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.24 in /usr/local/lib/python3.11/dist-packages (from segmentation_models_pytorch) (0.31.1)\n",
            "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.11/dist-packages (from segmentation_models_pytorch) (2.0.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from segmentation_models_pytorch) (11.2.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from segmentation_models_pytorch) (0.5.3)\n",
            "Requirement already satisfied: timm>=0.9 in /usr/local/lib/python3.11/dist-packages (from segmentation_models_pytorch) (1.0.15)\n",
            "Requirement already satisfied: torch>=1.8 in /usr/local/lib/python3.11/dist-packages (from segmentation_models_pytorch) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9 in /usr/local/lib/python3.11/dist-packages (from segmentation_models_pytorch) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from segmentation_models_pytorch) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (1.1.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation_models_pytorch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation_models_pytorch) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8->segmentation_models_pytorch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8->segmentation_models_pytorch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8->segmentation_models_pytorch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8->segmentation_models_pytorch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8->segmentation_models_pytorch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8->segmentation_models_pytorch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8->segmentation_models_pytorch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8->segmentation_models_pytorch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8->segmentation_models_pytorch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation_models_pytorch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation_models_pytorch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation_models_pytorch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8->segmentation_models_pytorch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation_models_pytorch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation_models_pytorch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8->segmentation_models_pytorch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8->segmentation_models_pytorch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.24->segmentation_models_pytorch) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.24->segmentation_models_pytorch) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.24->segmentation_models_pytorch) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.24->segmentation_models_pytorch) (2025.4.26)\n",
            "Downloading segmentation_models_pytorch-0.5.0-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m107.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, segmentation_models_pytorch\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 segmentation_models_pytorch-0.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install segmentation_models_pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euaoRKTOQJ69"
      },
      "source": [
        "На этом этапе осуществляется подключение датасета, представленного в формате COCO — популярной структуры данных, содержащей изображения с соответствующими метками и описанием объектов. Для работы с этим форматом создаётся пользовательский класс, который отвечает за генерацию сегментационных масок на основе аннотационной информации. Эти маски формируют основу для обучения моделей, определяющих, какие области изображения принадлежат целевым элементам сцены, а какие подлежат игнорированию."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTVSuJynQJ69",
        "outputId": "72a41681-0b4d-46de-ccdf-6e851461a858"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import segmentation_models_pytorch as smp\n",
        "from pycocotools.coco import COCO\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "AO7CZ3yGQJ69"
      },
      "outputs": [],
      "source": [
        "class PlantSegmentationLoader(Dataset):\n",
        "    def __init__(self, root_dir, label_file, preprocessor=None):\n",
        "        super().__init__()\n",
        "        self.root_dir = root_dir\n",
        "        self.annotations = COCO(label_file)\n",
        "        self.record_ids = list(self.annotations.imgs.keys())\n",
        "        self.category_map = self._build_category_index()\n",
        "        self.preprocessor = preprocessor\n",
        "\n",
        "    def _build_category_index(self):\n",
        "        categories = self.annotations.loadCats(self.annotations.getCatIds())\n",
        "        return {entry[\"id\"]: idx + 1 for idx, entry in enumerate(categories)}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.record_ids)\n",
        "\n",
        "    def _get_image(self, file_name):\n",
        "        full_path = os.path.join(self.root_dir, file_name)\n",
        "        img_data = cv2.imread(full_path)\n",
        "        if img_data is None:\n",
        "            raise IOError(f\"Cannot read image file: {full_path}\")\n",
        "        return cv2.cvtColor(img_data, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    def _compose_mask(self, annotations_list, shape):\n",
        "        label_mask = np.zeros(shape, dtype=np.uint8)\n",
        "        for element in annotations_list:\n",
        "            category_id = element[\"category_id\"]\n",
        "            mapped_label = self.category_map.get(category_id, 0)\n",
        "            temp_mask = self.annotations.annToMask(element)\n",
        "            label_mask[temp_mask.astype(bool)] = mapped_label\n",
        "        return label_mask\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        current_id = self.record_ids[index]\n",
        "        meta_info = self.annotations.loadImgs(current_id)[0]\n",
        "        image_array = self._get_image(meta_info[\"file_name\"])\n",
        "\n",
        "        annotation_ids = self.annotations.getAnnIds(imgIds=current_id)\n",
        "        annotation_data = self.annotations.loadAnns(annotation_ids)\n",
        "        mask_array = self._compose_mask(annotation_data, (meta_info[\"height\"], meta_info[\"width\"]))\n",
        "\n",
        "        if self.preprocessor:\n",
        "            result = self.preprocessor(image=image_array, mask=mask_array)\n",
        "            image_array, mask_array = result[\"image\"], result[\"mask\"]\n",
        "\n",
        "        return image_array, mask_array.long()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-31PPQqpQJ6-"
      },
      "source": [
        "### b. Метрики качества"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sOGcpZRQJ6-"
      },
      "source": [
        "Для количественной оценки результатов работы моделей будет применён F1 score, выступающий основным показателем качества в задачах сегментации. В качестве дополнительного критерия анализа точности перекрытия предсказанных и истинных областей объектов используется метрика Intersection over Union (IoU)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHR-QzbdQJ6-"
      },
      "source": [
        "## 2. Создание бейзлайна и оценка качества\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HaVf2bqQJ6-",
        "outputId": "2575fadb-8ba7-4767-c951-de717d11d04d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu118"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmHfnifVQJ6-"
      },
      "source": [
        "В рамках подготовки данных осуществляется инициализация набора изображений с аннотациями и формирование специализированных загрузчиков данных (DataLoaders), предназначенных для эффективной подачи информации в модель в процессе обучения и валидации. Количество категорий объектов увеличивается на единицу, поскольку дополнительно вводится специальный класс, обозначающий фон изображения, который необходим для корректной работы алгоритма сегментации."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZL2WyKKWQJ6-",
        "outputId": "00cf18b2-f37d-4b71-c217-1f037c813f91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        }
      ],
      "source": [
        "import albumentations as albu\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Конфигурация аугментаций\n",
        "def get_training_pipeline():\n",
        "    return albu.Compose([\n",
        "        albu.Resize(256, 256),\n",
        "        albu.HorizontalFlip(p=0.5),\n",
        "        albu.RandomCrop(224, 224),\n",
        "        albu.Normalize(),\n",
        "        ToTensorV2()\n",
        "    ])\n",
        "\n",
        "def get_validation_pipeline():\n",
        "    return albu.Compose([\n",
        "        albu.Resize(224, 224),\n",
        "        albu.Normalize(),\n",
        "        ToTensorV2()\n",
        "    ])\n",
        "\n",
        "train_images = \"data7/semantic-segmentation-of-plants.v2i.coco-segmentation/train\"\n",
        "train_labels = \"data7/semantic-segmentation-of-plants.v2i.coco-segmentation/train/train.json\"\n",
        "\n",
        "val_images = \"data7/semantic-segmentation-of-plants.v2i.coco-segmentation/valid\"\n",
        "val_labels = \"data7/semantic-segmentation-of-plants.v2i.coco-segmentation/valid/valid.json\"\n",
        "\n",
        "# Создание датасетов\n",
        "training_set = PlantSegmentationLoader(\n",
        "    root_dir=train_images,\n",
        "    label_file=train_labels,\n",
        "    preprocessor=get_training_pipeline()\n",
        ")\n",
        "\n",
        "validation_set = PlantSegmentationLoader(\n",
        "    root_dir=val_images,\n",
        "    label_file=val_labels,\n",
        "    preprocessor=get_validation_pipeline()\n",
        ")\n",
        "\n",
        "# Даталоадеры\n",
        "batch_sz = 32\n",
        "\n",
        "train_batcher = DataLoader(\n",
        "    dataset=training_set,\n",
        "    batch_size=batch_sz,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "val_batcher = DataLoader(\n",
        "    dataset=validation_set,\n",
        "    batch_size=batch_sz,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "#  Количество классов\n",
        "number_of_classes = len(training_set.category_map) + 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaO-7Wz_QJ6_"
      },
      "source": [
        "Реализуем вспомогательную функцию, предназначенную для анализа промежуточных результатов обучения модели. Этот метод автоматически рассчитывает ключевые метрики качества на валидационном наборе данных, обеспечивая возможность оперативно отслеживать прогресс и стабильность процесса обучения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "zYlji8GnQJ6_"
      },
      "outputs": [],
      "source": [
        "import segmentation_models_pytorch as smp\n",
        "from segmentation_models_pytorch.metrics.functional import get_stats, iou_score, f1_score\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def calculate_total_loss(predictions, ground_truth, categories):\n",
        "    dice = smp.losses.DiceLoss(mode='multiclass')\n",
        "    ce = nn.CrossEntropyLoss()\n",
        "    return dice(predictions, ground_truth) + ce(predictions, ground_truth)\n",
        "\n",
        "def evaluate_model(net, dataloader, class_count):\n",
        "    net.eval()\n",
        "    cumulative = {\"loss\": 0.0, \"iou\": 0.0, \"f1\": 0.0}\n",
        "    batches = len(dataloader)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_tensor, target_mask = batch\n",
        "            input_tensor = input_tensor.to(device)\n",
        "            target_mask = target_mask.to(device)\n",
        "\n",
        "            output_logits = net(input_tensor)\n",
        "            batch_loss = calculate_total_loss(output_logits, target_mask, class_count)\n",
        "            cumulative[\"loss\"] += batch_loss.item()\n",
        "\n",
        "            predictions = output_logits.argmax(dim=1)\n",
        "            true_pos, false_pos, false_neg, true_neg = get_stats(\n",
        "                predictions,\n",
        "                target_mask,\n",
        "                mode=\"multiclass\",\n",
        "                num_classes=class_count\n",
        "            )\n",
        "\n",
        "            cumulative[\"iou\"] += iou_score(true_pos, false_pos, false_neg, true_neg, reduction=\"micro\").item()\n",
        "            cumulative[\"f1\"]  += f1_score(true_pos, false_pos, false_neg, true_neg, reduction=\"micro\").item()\n",
        "\n",
        "    averaged_results = {key: val / batches for key, val in cumulative.items()}\n",
        "    return averaged_results\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YDQjP6bQJ6_"
      },
      "source": [
        "в качестве сверточной архитектуры выбрана модифицированная версия U-Net, использующая в качестве кодирующего блока предварительно обученную сеть ResNet34, что позволяет повысить качество извлечения признаков. Параллельно применяется трансформерная архитектура Segformer, в которой встраиваемый энкодер MiT-B0 отвечает за обработку входных данных и генерацию представлений объектов. Для повышения производительности вычислений и ускорения обучения модели переносятся на графический процессор с помощью конструкции .to(device), позволяющей использовать возможности CUDA.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272,
          "referenced_widgets": [
            "04bd65b7ec2747c8965a9ef6942a6fb4",
            "73bea592279d4085a73fbb66157d20fb",
            "55afc53bcb5e4538b41e88b8e3894626",
            "38f08ecefd6f4457bbf4849fd2b5d932",
            "3361aec9b57f479292d5c076a58da839",
            "ffde8306dcfb4f0d89a3917874127137",
            "62f0840ca12a46249ccbf6772661a3fa",
            "b5ef3d89b3c840e6806bfd794ba47cd5",
            "c62f9ce60861456bb0a3a9505ed9a0e2",
            "b93ec0bde594430383d10248514e350f",
            "bd46baaf36a04053ae740956f33d0a40",
            "e98629eb9f164a6f99370ba570ea4d6f",
            "d369af2f710b46dcaceb28fc80420e6b",
            "082e7f1957b246deaa2363fd54f23295",
            "95a16eccd0b642c1b5b51de674b6254c",
            "46432e6daf7746b88f56efa1eb1f109a",
            "1984e313ab6046719ae2a080d8b30d77",
            "f56fa29a277949738f9304926e07ccd9",
            "d76c714f360641a0b4cbc5c74946c22a",
            "33db9b6887684cdd96af2ad362834e35",
            "1923246178a0482cadd7ab3785032843",
            "d6f035dd61754a549dcde0f0a3fa3884",
            "ad6f90a42c434f46a85215e8239cbe54",
            "56cf6c31ae434473855d69ce2107e95e",
            "573c03adfac740a8abcf61ab3a7f15f6",
            "ebc288621bfd404985e208512c7fda4a",
            "a612c2bc09964c33b16e949959820c0e",
            "9e966d6c1b1d485e9645d74b6472a6d1",
            "d3f4b29f0bff4ddb99da6bb303af7c69",
            "9d3b9818309149c99477fc6b26cb4563",
            "3be53c23ea9a4e299b9348f141e5846b",
            "2a645f01abe147a595e4abe2e71817d5",
            "a49a8ebfbbb44075bf3ec49ed32e405c",
            "a46b14dc783f4661aab41ed77d477d60",
            "7d25f7159b0544c393fb898122b6d57b",
            "34175474908f460ca23c67f6e6087d11",
            "0b62eb5b07e14634bf18701950e61b5e",
            "126843c63cfb48dc9016a7568000ee06",
            "ed8a7bf35ee1441eb262d5d447b178fd",
            "e740273f7061443491607258da6b1f21",
            "39f5f8c0f3f74212bc3748b089b15261",
            "8fd9d45701ba49eabcd69bdb5e415ae4",
            "ab07348ee3dc4540af5724f4df86e6e6",
            "4931c869baa547f7905cf0c152f9f9a9"
          ]
        },
        "id": "S1O_EjPGQJ6_",
        "outputId": "789a1792-7318-4fe2-9a99-11b31e4e25fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/156 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "04bd65b7ec2747c8965a9ef6942a6fb4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/87.3M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e98629eb9f164a6f99370ba570ea4d6f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/135 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ad6f90a42c434f46a85215e8239cbe54"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/14.3M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a46b14dc783f4661aab41ed77d477d60"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "def initialize_unet(backbone=\"resnet34\", pretrained=\"imagenet\", output_classes=number_of_classes):\n",
        "    model_instance = smp.Unet(\n",
        "        encoder_name=backbone,\n",
        "        encoder_weights=pretrained,\n",
        "        classes=output_classes,\n",
        "        activation=None\n",
        "    )\n",
        "    return model_instance.to(device)\n",
        "\n",
        "def initialize_segformer(backbone_variant=\"mit_b0\", pretrained=\"imagenet\", input_channels=3, output_classes=number_of_classes):\n",
        "    segmentation_network = smp.Segformer(\n",
        "        encoder_name=backbone_variant,\n",
        "        encoder_weights=pretrained,\n",
        "        in_channels=input_channels,\n",
        "        classes=output_classes,\n",
        "        activation=None\n",
        "    )\n",
        "    return segmentation_network.to(device)\n",
        "\n",
        "unet_architecture = initialize_unet()\n",
        "segformer_architecture = initialize_segformer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Zh8F_C2QJ6_"
      },
      "source": [
        "Создаётся функция обучения, которая организует процесс оптимизации модели на основе обучающего набора данных. Функция также обеспечивает удобное отображение ключевых статистических показателей после каждой эпохи"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "vDyvTQ6-QJ6_"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import segmentation_models_pytorch as smp\n",
        "\n",
        "def compute_combined_loss(predictions, ground_truth):\n",
        "    dice_loss_fn = smp.losses.DiceLoss(mode=\"multiclass\")\n",
        "    cross_entropy_fn = nn.CrossEntropyLoss()\n",
        "    return dice_loss_fn(predictions, ground_truth) + cross_entropy_fn(predictions, ground_truth)\n",
        "\n",
        "def train_segmentation_network(network, train_data, val_data, epochs_count, learning_rate=1e-3):\n",
        "    optimizer_engine = optim.Adam(network.parameters(), lr=learning_rate)\n",
        "\n",
        "    for current_epoch in range(1, epochs_count + 1):\n",
        "        network.train()\n",
        "        cumulative_train_loss = 0.0\n",
        "\n",
        "        batch_iterator = tqdm(train_data, desc=f\"Epoch {current_epoch}/{epochs_count} - Training\", leave=False)\n",
        "\n",
        "        for batch_images, batch_masks in batch_iterator:\n",
        "            batch_images = batch_images.to(device)\n",
        "            batch_masks = batch_masks.to(device)\n",
        "\n",
        "            optimizer_engine.zero_grad()\n",
        "            predictions = network(batch_images)\n",
        "            loss_value = compute_combined_loss(predictions, batch_masks)\n",
        "            loss_value.backward()\n",
        "            optimizer_engine.step()\n",
        "\n",
        "            cumulative_train_loss += loss_value.item()\n",
        "\n",
        "        validation_metrics = evaluate_model(network, val_data, class_count=number_of_classes)\n",
        "        average_train_loss = cumulative_train_loss / len(train_data)\n",
        "\n",
        "        print(f\"[{current_epoch:02d}/{epochs_count}] \"\n",
        "              f\"Train Loss: {average_train_loss:.5f} | \"\n",
        "              f\"Val Loss: {validation_metrics['loss']:.5f} | \"\n",
        "              f\"IoU: {validation_metrics['iou']:.5f} | \"\n",
        "              f\"F1: {validation_metrics['f1']:.5f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIIHWqrkQJ6_"
      },
      "source": [
        "Теперь запустим обучение"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0srIaKQgQJ6_",
        "outputId": "f9cee226-e3e0-4c6c-cae0-d52a4c7823a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 01 | train loss: 1.9078 | val loss:   6.8179 | iou:        0.0594 | f1:         0.1122\n",
            "epoch 02 | train loss: 1.2718 | val loss:   5.7178 | iou:        0.0753 | f1:         0.1400\n",
            "epoch 03 | train loss: 1.0316 | val loss:   4.1888 | iou:        0.1367 | f1:         0.2405\n",
            "epoch 04 | train loss: 0.8894 | val loss:   3.2286 | iou:        0.2089 | f1:         0.3457\n",
            "epoch 05 | train loss: 0.8209 | val loss:   1.8287 | iou:        0.4224 | f1:         0.5939\n",
            "epoch 06 | train loss: 0.7167 | val loss:   1.3039 | iou:        0.5905 | f1:         0.7425\n",
            "epoch 07 | train loss: 0.6153 | val loss:   1.7420 | iou:        0.4819 | f1:         0.6504\n",
            "epoch 08 | train loss: 0.5695 | val loss:   1.7457 | iou:        0.4409 | f1:         0.6120\n",
            "epoch 09 | train loss: 0.5170 | val loss:   1.1812 | iou:        0.6114 | f1:         0.7589\n",
            "epoch 10 | train loss: 0.5029 | val loss:   1.1010 | iou:        0.6526 | f1:         0.7898\n",
            "epoch 11 | train loss: 0.4487 | val loss:   1.1314 | iou:        0.6525 | f1:         0.7897\n",
            "epoch 12 | train loss: 0.4198 | val loss:   1.0926 | iou:        0.6585 | f1:         0.7941\n",
            "epoch 13 | train loss: 0.4999 | val loss:   1.1612 | iou:        0.6236 | f1:         0.7682\n",
            "epoch 14 | train loss: 0.5353 | val loss:   1.4305 | iou:        0.5391 | f1:         0.7005\n",
            "epoch 15 | train loss: 0.4539 | val loss:   1.5374 | iou:        0.4079 | f1:         0.5795\n",
            "epoch 16 | train loss: 0.5173 | val loss:   38.6557 | iou:        0.0816 | f1:         0.1510\n",
            "epoch 17 | train loss: 0.5312 | val loss:   3.1861 | iou:        0.3323 | f1:         0.4989\n",
            "epoch 18 | train loss: 0.4716 | val loss:   1.5124 | iou:        0.5611 | f1:         0.7188\n",
            "epoch 19 | train loss: 0.4713 | val loss:   1.0747 | iou:        0.6863 | f1:         0.8139\n",
            "epoch 20 | train loss: 0.4235 | val loss:   1.1001 | iou:        0.6902 | f1:         0.8167\n",
            "epoch 21 | train loss: 0.4419 | val loss:   1.2085 | iou:        0.6503 | f1:         0.7881\n",
            "epoch 22 | train loss: 0.3325 | val loss:   1.1165 | iou:        0.6614 | f1:         0.7962\n",
            "epoch 23 | train loss: 0.3561 | val loss:   1.0538 | iou:        0.7032 | f1:         0.8257\n",
            "epoch 24 | train loss: 0.2902 | val loss:   1.1108 | iou:        0.6567 | f1:         0.7928\n",
            "epoch 25 | train loss: 0.2710 | val loss:   1.1744 | iou:        0.6291 | f1:         0.7724\n",
            "epoch 26 | train loss: 0.3085 | val loss:   1.1379 | iou:        0.6647 | f1:         0.7986\n",
            "epoch 27 | train loss: 0.3234 | val loss:   1.1998 | iou:        0.6616 | f1:         0.7963\n",
            "epoch 28 | train loss: 0.2633 | val loss:   1.2340 | iou:        0.6334 | f1:         0.7755\n",
            "epoch 29 | train loss: 0.2654 | val loss:   1.1924 | iou:        0.6353 | f1:         0.7770\n",
            "epoch 30 | train loss: 0.2792 | val loss:   1.2156 | iou:        0.6397 | f1:         0.7802\n"
          ]
        }
      ],
      "source": [
        "total_epochs = 30\n",
        "initial_lr = 1e-3\n",
        "\n",
        "train_segmentation_network(\n",
        "    network=unet_architecture,\n",
        "    train_data=train_batcher,\n",
        "    val_data=val_batcher,\n",
        "    epochs_count=total_epochs,\n",
        "    learning_rate=initial_lr\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwYRtVGVQJ6_"
      },
      "source": [
        "Результат обучения довольно хорош, но далёк от идеала: f1 = 0.7802"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFMZECE0QJ7A",
        "outputId": "3594ca71-7bdc-4689-e950-03385fdd8e9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 01 | train loss: 1.7994 | val loss:   4.7516 | iou:        0.2541 | f1:         0.4052\n",
            "epoch 02 | train loss: 1.0141 | val loss:   1.2042 | iou:        0.6510 | f1:         0.7886\n",
            "epoch 03 | train loss: 0.7554 | val loss:   1.3775 | iou:        0.6297 | f1:         0.7728\n",
            "epoch 04 | train loss: 0.6093 | val loss:   0.8074 | iou:        0.6969 | f1:         0.8214\n",
            "epoch 05 | train loss: 0.5342 | val loss:   0.8031 | iou:        0.7326 | f1:         0.8457\n",
            "epoch 06 | train loss: 0.4449 | val loss:   0.8191 | iou:        0.7186 | f1:         0.8363\n",
            "epoch 07 | train loss: 0.4322 | val loss:   1.1862 | iou:        0.6402 | f1:         0.7806\n",
            "epoch 08 | train loss: 0.3771 | val loss:   1.1581 | iou:        0.6674 | f1:         0.8005\n",
            "epoch 09 | train loss: 0.3481 | val loss:   1.1137 | iou:        0.6674 | f1:         0.8005\n",
            "epoch 10 | train loss: 0.3750 | val loss:   1.2271 | iou:        0.6106 | f1:         0.7582\n",
            "epoch 11 | train loss: 0.3218 | val loss:   1.0348 | iou:        0.6866 | f1:         0.8142\n",
            "epoch 12 | train loss: 0.3080 | val loss:   1.2700 | iou:        0.6396 | f1:         0.7802\n",
            "epoch 13 | train loss: 0.2977 | val loss:   1.1573 | iou:        0.6667 | f1:         0.8000\n",
            "epoch 14 | train loss: 0.2847 | val loss:   1.0504 | iou:        0.6867 | f1:         0.8142\n",
            "epoch 15 | train loss: 0.2677 | val loss:   1.0886 | iou:        0.6686 | f1:         0.8014\n",
            "epoch 16 | train loss: 0.2513 | val loss:   0.9058 | iou:        0.7054 | f1:         0.8272\n",
            "epoch 17 | train loss: 0.2584 | val loss:   1.0247 | iou:        0.6766 | f1:         0.8071\n",
            "epoch 18 | train loss: 0.2448 | val loss:   1.1520 | iou:        0.6544 | f1:         0.7911\n",
            "epoch 19 | train loss: 0.2177 | val loss:   1.1106 | iou:        0.6971 | f1:         0.8215\n",
            "epoch 20 | train loss: 0.2141 | val loss:   1.1091 | iou:        0.6815 | f1:         0.8106\n",
            "epoch 21 | train loss: 0.2165 | val loss:   1.0021 | iou:        0.7014 | f1:         0.8245\n",
            "epoch 22 | train loss: 0.2014 | val loss:   0.9963 | iou:        0.6985 | f1:         0.8225\n",
            "epoch 23 | train loss: 0.2007 | val loss:   1.1828 | iou:        0.6755 | f1:         0.8063\n",
            "epoch 24 | train loss: 0.1982 | val loss:   1.0436 | iou:        0.6848 | f1:         0.8129\n",
            "epoch 25 | train loss: 0.1922 | val loss:   1.0121 | iou:        0.7016 | f1:         0.8246\n",
            "epoch 26 | train loss: 0.1785 | val loss:   0.9397 | iou:        0.7171 | f1:         0.8352\n",
            "epoch 27 | train loss: 0.1903 | val loss:   1.0457 | iou:        0.7156 | f1:         0.8342\n",
            "epoch 28 | train loss: 0.1882 | val loss:   1.1371 | iou:        0.6926 | f1:         0.8184\n",
            "epoch 29 | train loss: 0.1771 | val loss:   1.1712 | iou:        0.6889 | f1:         0.8158\n",
            "epoch 30 | train loss: 0.1750 | val loss:   1.2170 | iou:        0.6740 | f1:         0.8053\n"
          ]
        }
      ],
      "source": [
        "segformer_epochs = 30\n",
        "segformer_lr = 1e-3\n",
        "\n",
        "train_segmentation_network(\n",
        "    network=segformer_architecture,\n",
        "    train_data=train_batcher,\n",
        "    val_data=val_batcher,\n",
        "    epochs_count=segformer_epochs,\n",
        "    learning_rate=segformer_lr\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwWTzl3CQJ7A"
      },
      "source": [
        "Здесь f1=0.823 - это лучше чем у cnn модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoY-NFy_QJ7A"
      },
      "source": [
        "## 3. Улучшение бейзлайна"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NajNtjjQJ7A"
      },
      "source": [
        "### Гипотезы\n",
        "\n",
        "Для увеличения разнообразия обучающих данных и повышения устойчивости модели к различным искажениям, в процесс подготовки изображений интегрируются дополнительные агрессивные методы аугментации, включая случайные изменения цвета, яркости, контраста, а также повороты изображения. В качестве алгоритма оптимизации выбран AdamW, обладающий улучшенной устойчивостью к переобучению за счёт введения веса регуляризации. Кроме того, добавлен механизм управления скоростью обучения (Scheduler), который позволяет динамически корректировать значение learning rate в процессе обучения. Параметры обучения также были адаптированы: размер батча уменьшён до 16, а стартовая скорость обучения снижена для обеспечения более стабильной сходимости."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "e2d92004905743fd8fbe251f84fb4d59",
            "5b1ce771bb1846e7a2db7726b7597f12",
            "8faba61d6c95488e8926ac701ecb0a39",
            "20442f1f5c7347c49a2f0a3b959f1e5d",
            "132047ff9df64bce8ce349a164485aea",
            "80fb797847764f5ea50db2b38d310bab",
            "d95da25a68e647a89b979889efb26f41",
            "a7ad8bf84b9e451baedb9121b4b4b263",
            "7f64ab819d724f5cbbf53efb2591a41d",
            "8c50f0ba73c94529841823f21fa2b0db",
            "505a023a0a8a44db970c447af93fb37e",
            "ba6aaa44bd7449a7829f6a5fd97e9a34",
            "2b9d1578fc3e46abb2ff569a3cc60e54",
            "5fc213eb3b314423927013f830747731",
            "0cdae9b0fc7b46d49196bf2e696d8d14",
            "29c4d15ecca145edb7467fa56fce89ba",
            "781aeff7492b4898abfa86aa3f1175a8",
            "30fbdd334ed643d0a96dbad1168a2927",
            "1ec3f0015aa34b468f7d9e44a8cf2244",
            "89cb8773f9d3413eb80f45d40d6efc9a",
            "4f76d09145504ec4a44ade6d0c62248c",
            "cdd66c7cf76740a1a4d6b3da0706abec"
          ]
        },
        "id": "-Agp9KKVQJ7A",
        "outputId": "7cd9bce2-bcd0-468c-deae-a851218a4f73"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/156 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e2d92004905743fd8fbe251f84fb4d59"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/102M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ba6aaa44bd7449a7829f6a5fd97e9a34"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Улучшённые аугментации\n",
        "enhanced_augmentations = albu.Compose([\n",
        "    albu.Resize(256, 256),\n",
        "    albu.HorizontalFlip(p=0.5),\n",
        "    albu.VerticalFlip(p=0.5),\n",
        "    albu.RandomRotate90(p=0.5),\n",
        "    albu.ColorJitter(p=0.5),\n",
        "    albu.RandomCrop(224, 224),\n",
        "    albu.Normalize(),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "# Переопределение трансформации и DataLoader\n",
        "training_set.preprocessor = enhanced_augmentations\n",
        "\n",
        "refined_batcher = DataLoader(\n",
        "    dataset=training_set,\n",
        "    batch_size=16,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "# Инициализация модели\n",
        "improved_model = smp.Unet(\n",
        "    encoder_name=\"resnet50\",\n",
        "    encoder_weights=\"imagenet\",\n",
        "    classes=number_of_classes,\n",
        "    activation=None\n",
        ").to(device)\n",
        "\n",
        "# Оптимизатор, Scheduler и Loss\n",
        "optimizer_config = optim.AdamW(improved_model.parameters(), lr=1e-4)\n",
        "lr_scheduler = CosineAnnealingLR(optimizer_config, T_max=10)\n",
        "\n",
        "dice_loss_fn = smp.losses.DiceLoss(mode=\"multiclass\")\n",
        "ce_loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def advanced_training_loop(net, train_data, val_data, total_epochs):\n",
        "    for cycle in range(1, total_epochs + 1):\n",
        "        net.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        data_iterator = tqdm(train_data, desc=f\"Epoch {cycle}/{total_epochs} - Advanced Training\", leave=False)\n",
        "\n",
        "        for batch_images, batch_labels in data_iterator:\n",
        "            batch_images = batch_images.to(device)\n",
        "            batch_labels = batch_labels.to(device)\n",
        "\n",
        "            optimizer_config.zero_grad()\n",
        "            outputs = net(batch_images)\n",
        "            loss_value = dice_loss_fn(outputs, batch_labels) + ce_loss_fn(outputs, batch_labels)\n",
        "            loss_value.backward()\n",
        "            optimizer_config.step()\n",
        "\n",
        "            running_loss += loss_value.item()\n",
        "\n",
        "        lr_scheduler.step()\n",
        "\n",
        "        validation_results = evaluate_model(net, val_data, class_count=number_of_classes)\n",
        "        avg_train_loss = running_loss / len(train_data)\n",
        "\n",
        "        print(f\"[{cycle:02d}/{total_epochs}] \"\n",
        "              f\"Train Loss: {avg_train_loss:.5f} | \"\n",
        "              f\"Val Loss: {validation_results['loss']:.5f} | \"\n",
        "              f\"IoU: {validation_results['iou']:.5f} | \"\n",
        "              f\"F1: {validation_results['f1']:.5f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rj9LxBEqQJ7A"
      },
      "source": [
        "Обучим бейзлайн cnn модель:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HyLy4O8QJ7A",
        "outputId": "108a09f9-ad0b-4cb5-c0b2-0c8ae9d658cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 01 | train loss: 2.3181 | val loss:   2.2078 | iou:        0.1157 | f1:         0.2073\n",
            "epoch 02 | train loss: 1.9840 | val loss:   2.1235 | iou:        0.2210 | f1:         0.3620\n",
            "epoch 03 | train loss: 1.7767 | val loss:   2.0036 | iou:        0.3519 | f1:         0.5205\n",
            "epoch 04 | train loss: 1.6386 | val loss:   1.7565 | iou:        0.4932 | f1:         0.6606\n",
            "epoch 05 | train loss: 1.5496 | val loss:   1.7404 | iou:        0.5195 | f1:         0.6837\n",
            "epoch 06 | train loss: 1.4935 | val loss:   1.6610 | iou:        0.5710 | f1:         0.7269\n",
            "epoch 07 | train loss: 1.4951 | val loss:   1.6279 | iou:        0.5999 | f1:         0.7499\n",
            "epoch 08 | train loss: 1.4316 | val loss:   1.6192 | iou:        0.6053 | f1:         0.7542\n",
            "epoch 09 | train loss: 1.4173 | val loss:   1.6077 | iou:        0.6133 | f1:         0.7603\n",
            "epoch 10 | train loss: 1.4186 | val loss:   1.6026 | iou:        0.6163 | f1:         0.7626\n",
            "epoch 11 | train loss: 1.3902 | val loss:   1.5948 | iou:        0.6204 | f1:         0.7657\n",
            "epoch 12 | train loss: 1.4154 | val loss:   1.5949 | iou:        0.6178 | f1:         0.7638\n",
            "epoch 13 | train loss: 1.3677 | val loss:   1.5927 | iou:        0.6248 | f1:         0.7691\n",
            "epoch 14 | train loss: 1.3794 | val loss:   1.5997 | iou:        0.6206 | f1:         0.7659\n",
            "epoch 15 | train loss: 1.3497 | val loss:   1.5929 | iou:        0.6207 | f1:         0.7660\n",
            "epoch 16 | train loss: 1.3080 | val loss:   1.5790 | iou:        0.6303 | f1:         0.7733\n",
            "epoch 17 | train loss: 1.3137 | val loss:   1.5029 | iou:        0.6626 | f1:         0.7971\n",
            "epoch 18 | train loss: 1.2193 | val loss:   1.4424 | iou:        0.6694 | f1:         0.8020\n",
            "epoch 19 | train loss: 1.2138 | val loss:   1.4519 | iou:        0.6733 | f1:         0.8047\n",
            "epoch 20 | train loss: 1.1136 | val loss:   1.3510 | iou:        0.6813 | f1:         0.8105\n",
            "epoch 21 | train loss: 1.0708 | val loss:   1.3136 | iou:        0.7001 | f1:         0.8236\n",
            "epoch 22 | train loss: 1.0378 | val loss:   1.3581 | iou:        0.6619 | f1:         0.7965\n",
            "epoch 23 | train loss: 0.9755 | val loss:   1.3262 | iou:        0.6801 | f1:         0.8096\n",
            "epoch 24 | train loss: 0.9561 | val loss:   1.2983 | iou:        0.6722 | f1:         0.8040\n",
            "epoch 25 | train loss: 0.8953 | val loss:   1.2390 | iou:        0.6949 | f1:         0.8200\n",
            "epoch 26 | train loss: 0.9055 | val loss:   1.2608 | iou:        0.6778 | f1:         0.8080\n",
            "epoch 27 | train loss: 0.8681 | val loss:   1.2627 | iou:        0.6738 | f1:         0.8051\n",
            "epoch 28 | train loss: 0.8279 | val loss:   1.2518 | iou:        0.6806 | f1:         0.8099\n",
            "epoch 29 | train loss: 0.8457 | val loss:   1.2285 | iou:        0.6890 | f1:         0.8159\n",
            "epoch 30 | train loss: 0.8268 | val loss:   1.2045 | iou:        0.6944 | f1:         0.8196\n"
          ]
        }
      ],
      "source": [
        "improved_epochs = 30\n",
        "\n",
        "advanced_training_loop(\n",
        "    net=improved_model,\n",
        "    train_data=refined_batcher,\n",
        "    val_data=val_batcher,\n",
        "    total_epochs=improved_epochs\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMMWgmI2QJ7A"
      },
      "source": [
        "Наша гипотеза работает, но на мой взгляд недостаточно эффективно, f1 принял значение 0.8196"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OT0X9MNvQJ7B"
      },
      "source": [
        "Повторим для трансформерной модели:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "NSSzjnCxQJ7B"
      },
      "outputs": [],
      "source": [
        "import segmentation_models_pytorch as smp\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "refined_segformer = smp.Segformer(\n",
        "    encoder_name=\"mit_b0\",\n",
        "    encoder_weights=\"imagenet\",\n",
        "    in_channels=3,\n",
        "    classes=number_of_classes,\n",
        "    activation=None\n",
        ").to(device)\n",
        "\n",
        "segformer_optimizer = optim.AdamW(refined_segformer.parameters(), lr=1e-4)\n",
        "segformer_scheduler = optim.lr_scheduler.CosineAnnealingLR(segformer_optimizer, T_max=10)\n",
        "\n",
        "dice_metric_fn = smp.losses.DiceLoss(mode=\"multiclass\")\n",
        "cross_entropy_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def run_segformer_training(model_core, train_data, val_data, epochs_total):\n",
        "    for stage in range(1, epochs_total + 1):\n",
        "        model_core.train()\n",
        "        cumulative_loss = 0.0\n",
        "\n",
        "        batch_bar = tqdm(train_data, desc=f\"Epoch {stage}/{epochs_total} - Segformer Training\", leave=False)\n",
        "\n",
        "        for image_batch, mask_batch in batch_bar:\n",
        "            image_batch = image_batch.to(device)\n",
        "            mask_batch = mask_batch.to(device)\n",
        "\n",
        "            segformer_optimizer.zero_grad()\n",
        "            predictions = model_core(image_batch)\n",
        "            batch_loss = dice_metric_fn(predictions, mask_batch) + cross_entropy_fn(predictions, mask_batch)\n",
        "            batch_loss.backward()\n",
        "            segformer_optimizer.step()\n",
        "\n",
        "            cumulative_loss += batch_loss.item()\n",
        "\n",
        "        segformer_scheduler.step()\n",
        "        evaluation_metrics = evaluate_model(model_core, val_data, class_count=number_of_classes)\n",
        "        avg_epoch_loss = cumulative_loss / len(train_data)\n",
        "\n",
        "        print(f\"[{stage:02d}/{epochs_total}] \"\n",
        "              f\"Train Loss: {avg_epoch_loss:.5f} | \"\n",
        "              f\"Val Loss: {evaluation_metrics['loss']:.5f} | \"\n",
        "              f\"IoU: {evaluation_metrics['iou']:.5f} | \"\n",
        "              f\"F1: {evaluation_metrics['f1']:.5f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slIO20BdQJ7B"
      },
      "source": [
        "Обучим модель:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wX65VVgvQJ7B",
        "outputId": "e7076a0e-f229-419e-ec2f-37f726a8c863"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 01 | train loss: 1.7638 | val loss:   1.5123 | ioo:        0.4816 | f1:         0.6501\n",
            "epoch 02 | train loss: 1.1506 | val loss:   1.1460 | ioo:        0.6149 | f1:         0.7615\n",
            "epoch 03 | train loss: 0.8769 | val loss:   0.9921 | ioo:        0.6575 | f1:         0.7934\n",
            "epoch 04 | train loss: 0.7844 | val loss:   0.8785 | ioo:        0.7039 | f1:         0.8263\n",
            "epoch 05 | train loss: 0.7212 | val loss:   0.9437 | ioo:        0.6817 | f1:         0.8108\n",
            "epoch 06 | train loss: 0.6758 | val loss:   0.9220 | ioo:        0.6777 | f1:         0.8079\n",
            "epoch 07 | train loss: 0.6334 | val loss:   0.8835 | ioo:        0.6922 | f1:         0.8181\n",
            "epoch 08 | train loss: 0.6455 | val loss:   0.8980 | ioo:        0.6851 | f1:         0.8131\n",
            "epoch 09 | train loss: 0.6028 | val loss:   0.8996 | ioo:        0.6825 | f1:         0.8113\n",
            "epoch 10 | train loss: 0.6081 | val loss:   0.8910 | ioo:        0.6861 | f1:         0.8138\n",
            "epoch 11 | train loss: 0.5789 | val loss:   0.8973 | ioo:        0.6837 | f1:         0.8121\n",
            "epoch 12 | train loss: 0.6059 | val loss:   0.9031 | ioo:        0.6804 | f1:         0.8098\n",
            "epoch 13 | train loss: 0.5689 | val loss:   0.9045 | ioo:        0.6785 | f1:         0.8085\n",
            "epoch 14 | train loss: 0.5757 | val loss:   0.9162 | ioo:        0.6724 | f1:         0.8041\n",
            "epoch 15 | train loss: 0.5762 | val loss:   0.8987 | ioo:        0.6792 | f1:         0.8090\n",
            "epoch 16 | train loss: 0.5412 | val loss:   0.8902 | ioo:        0.6787 | f1:         0.8086\n",
            "epoch 17 | train loss: 0.5387 | val loss:   0.9111 | ioo:        0.6667 | f1:         0.8000\n",
            "epoch 18 | train loss: 0.5290 | val loss:   0.8822 | ioo:        0.6861 | f1:         0.8138\n",
            "epoch 19 | train loss: 0.5247 | val loss:   0.9056 | ioo:        0.6893 | f1:         0.8161\n",
            "epoch 20 | train loss: 0.4839 | val loss:   0.9503 | ioo:        0.6686 | f1:         0.8014\n",
            "epoch 21 | train loss: 0.4411 | val loss:   0.9943 | ioo:        0.6760 | f1:         0.8067\n",
            "epoch 22 | train loss: 0.4032 | val loss:   1.0536 | ioo:        0.6675 | f1:         0.8006\n",
            "epoch 23 | train loss: 0.4040 | val loss:   1.0539 | ioo:        0.6782 | f1:         0.8083\n",
            "epoch 24 | train loss: 0.4069 | val loss:   1.0440 | ioo:        0.6610 | f1:         0.7959\n",
            "epoch 25 | train loss: 0.3861 | val loss:   1.0968 | ioo:        0.6687 | f1:         0.8015\n",
            "epoch 26 | train loss: 0.4334 | val loss:   1.0742 | ioo:        0.6776 | f1:         0.8078\n",
            "epoch 27 | train loss: 0.3682 | val loss:   1.0386 | ioo:        0.6791 | f1:         0.8089\n",
            "epoch 28 | train loss: 0.3774 | val loss:   1.0345 | ioo:        0.6760 | f1:         0.8067\n",
            "epoch 29 | train loss: 0.3963 | val loss:   1.0362 | ioo:        0.6753 | f1:         0.8062\n",
            "epoch 30 | train loss: 0.3648 | val loss:   1.0495 | ioo:        0.6737 | f1:         0.8051\n"
          ]
        }
      ],
      "source": [
        "segformer_epochs_v2 = 30\n",
        "\n",
        "run_segformer_training(\n",
        "    model_core=refined_segformer,\n",
        "    train_data=refined_batcher,\n",
        "    val_data=val_batcher,\n",
        "    epochs_total=segformer_epochs_v2\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rG4edqiCQJ7C"
      },
      "source": [
        "f1 равный 0.8051 явно даёт понять, что бейзлайн трансформера мне улучшить не удалось и нужна иная гипотеза"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCCgaD9VQJ7C"
      },
      "source": [
        "## 4. Имплементация алгоритма машинного обучения\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yt_LiQy_n1R9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-eswZXoQJ7D"
      },
      "source": [
        "Здесь создаются собственные версии моделей: одна на основе сверточных слоёв, другая с использованием трансформерной архитектуры."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "rIgXkkNUQJ7D"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class FeatureBlock(nn.Module):\n",
        "    def __init__(self, inputs, outputs):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Conv2d(inputs, outputs, 3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(outputs, outputs, 3, padding=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "class PyramidUNetCore(nn.Module):\n",
        "    def __init__(self, categories_out):\n",
        "        super().__init__()\n",
        "\n",
        "        self.stage_a = FeatureBlock(3, 64)\n",
        "        self.stage_b = FeatureBlock(64, 128)\n",
        "        self.stage_c = FeatureBlock(128, 256)\n",
        "        self.bottleneck = FeatureBlock(256, 512)\n",
        "\n",
        "        self.downsample = nn.MaxPool2d(2)\n",
        "\n",
        "        self.up_b = nn.ConvTranspose2d(512, 256, 2, stride=2)\n",
        "        self.decode_b = FeatureBlock(512, 256)\n",
        "\n",
        "        self.up_c = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
        "        self.decode_c = FeatureBlock(256, 128)\n",
        "\n",
        "        self.up_d = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
        "        self.decode_d = FeatureBlock(128, 64)\n",
        "\n",
        "        self.final_projection = nn.Conv2d(64, categories_out, kernel_size=1)\n",
        "\n",
        "    def forward(self, input_map):\n",
        "        x1 = self.stage_a(input_map)\n",
        "        x2 = self.stage_b(self.downsample(x1))\n",
        "        x3 = self.stage_c(self.downsample(x2))\n",
        "        bridge = self.bottleneck(self.downsample(x3))\n",
        "\n",
        "        y1 = self.decode_b(torch.cat([self.up_b(bridge), x3], dim=1))\n",
        "        y2 = self.decode_c(torch.cat([self.up_c(y1), x2], dim=1))\n",
        "        y3 = self.decode_d(torch.cat([self.up_d(y2), x1], dim=1))\n",
        "\n",
        "        return self.final_projection(y3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "YPd9PhfGQJ7D"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class PatchTokenEmbedding(nn.Module):\n",
        "    def __init__(self, input_channels, embedding_dim, patch_dim):\n",
        "        super().__init__()\n",
        "        self.projection = nn.Conv2d(input_channels, embedding_dim, kernel_size=patch_dim, stride=patch_dim)\n",
        "\n",
        "    def forward(self, images):\n",
        "        return self.projection(images)\n",
        "\n",
        "class HybridVisionEncoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                 resolution=224, token_size=32, channels_in=3,\n",
        "                 embed_channels=128, heads=4, layers=2, class_count=number_of_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        assert resolution % token_size == 0, \"Image size must be divisible by patch size.\"\n",
        "        self.tokenizer = PatchTokenEmbedding(channels_in, embed_channels, token_size)\n",
        "\n",
        "        total_tokens = (resolution // token_size) ** 2\n",
        "        self.token_positions = nn.Parameter(torch.zeros(1, total_tokens, embed_channels))\n",
        "\n",
        "        transformer_block = nn.TransformerEncoderLayer(\n",
        "            d_model=embed_channels,\n",
        "            nhead=heads,\n",
        "            dim_feedforward=embed_channels * 2,\n",
        "            dropout=0.1,\n",
        "            activation='gelu'\n",
        "        )\n",
        "        self.encoder = nn.TransformerEncoder(transformer_block, num_layers=layers)\n",
        "\n",
        "        self.reconstruction = nn.Sequential(\n",
        "            nn.ConvTranspose2d(embed_channels, embed_channels, kernel_size=token_size, stride=token_size),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(embed_channels, embed_channels // 2, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(embed_channels // 2, class_count, kernel_size=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, batch_images):\n",
        "        features = self.tokenizer(batch_images)\n",
        "        batch_size, channel_count, height, width = features.shape\n",
        "\n",
        "        sequence = features.flatten(2).transpose(1, 2) + self.token_positions\n",
        "        sequence = sequence.permute(1, 0, 2)\n",
        "        transformed = self.encoder(sequence)\n",
        "        transformed = transformed.permute(1, 0, 2).transpose(1, 2).view(batch_size, channel_count, height, width)\n",
        "\n",
        "        return self.reconstruction(transformed)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9Q9ufBBQJ7D"
      },
      "source": [
        "Создана функция валидации для проверки качества собственных моделей. Она позволяет автоматически оценивать точность предсказаний на проверочных данных и выводить значения основных метрик"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "yCAhDBq6QJ7D"
      },
      "outputs": [],
      "source": [
        "import segmentation_models_pytorch as smp\n",
        "from segmentation_models_pytorch.metrics.functional import get_stats, iou_score, f1_score\n",
        "\n",
        "def compute_validation_loss(pred_map, target_map):\n",
        "    dice_metric = smp.losses.DiceLoss(mode=\"multiclass\")\n",
        "    ce_metric = nn.CrossEntropyLoss()\n",
        "    return dice_metric(pred_map, target_map) + ce_metric(pred_map, target_map)\n",
        "\n",
        "def assess_model_performance(model_core, data_iterator, categories):\n",
        "    model_core.eval()\n",
        "    metrics_accumulator = {\"loss\": 0.0, \"iou\": 0.0, \"f1\": 0.0}\n",
        "    batch_count = len(data_iterator)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for image_input, ground_truth in tqdm(data_iterator, desc=\"Evaluating...\", leave=False):\n",
        "            image_input = image_input.to(device)\n",
        "            ground_truth = ground_truth.to(device)\n",
        "\n",
        "            output_logits = model_core(image_input)\n",
        "            batch_loss = compute_validation_loss(output_logits, ground_truth)\n",
        "            metrics_accumulator[\"loss\"] += batch_loss.item()\n",
        "\n",
        "            predictions = output_logits.argmax(dim=1)\n",
        "            tp, fp, fn, tn = get_stats(\n",
        "                predictions,\n",
        "                ground_truth,\n",
        "                mode=\"multiclass\",\n",
        "                num_classes=categories\n",
        "            )\n",
        "\n",
        "            metrics_accumulator[\"iou\"] += iou_score(tp, fp, fn, tn, reduction=\"micro\").item()\n",
        "            metrics_accumulator[\"f1\"] += f1_score(tp, fp, fn, tn, reduction=\"micro\").item()\n",
        "\n",
        "    averaged_metrics = {metric: value / batch_count for metric, value in metrics_accumulator.items()}\n",
        "    return averaged_metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZbIEIUwQJ7E"
      },
      "source": [
        "Функция обучения для реализованных моделей:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "aoz288tMQJ7E"
      },
      "outputs": [],
      "source": [
        "from torch import optim\n",
        "\n",
        "def execute_custom_training(core_network, data_train, data_val, epoch_limit, initial_lr=1e-3):\n",
        "    optimizer_engine = optim.Adam(core_network.parameters(), lr=initial_lr)\n",
        "\n",
        "    for cycle_index in range(1, epoch_limit + 1):\n",
        "        core_network.train()\n",
        "        aggregate_loss = 0.0\n",
        "\n",
        "        progress_bar = tqdm(data_train, desc=f\"Cycle {cycle_index}/{epoch_limit} - Custom Train\", leave=False)\n",
        "\n",
        "        for batch_inputs, batch_targets in progress_bar:\n",
        "            batch_inputs = batch_inputs.to(device)\n",
        "            batch_targets = batch_targets.to(device)\n",
        "\n",
        "            optimizer_engine.zero_grad()\n",
        "            predicted_logits = core_network(batch_inputs)\n",
        "            total_loss = calculate_combined_loss(predicted_logits, batch_targets)\n",
        "            total_loss.backward()\n",
        "            optimizer_engine.step()\n",
        "\n",
        "            aggregate_loss += total_loss.item()\n",
        "\n",
        "        validation_scores = assess_model_performance(core_network, data_val, categories=number_of_classes)\n",
        "        average_train_loss = aggregate_loss / len(data_train)\n",
        "\n",
        "        print(f\"[{cycle_index:02d}/{epoch_limit}] \"\n",
        "              f\"Train Loss: {average_train_loss:.5f} | \"\n",
        "              f\"Val Loss: {validation_scores['loss']:.5f} | \"\n",
        "              f\"IoU: {validation_scores['iou']:.5f} | \"\n",
        "              f\"F1: {validation_scores['f1']:.5f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "dtes4mN_QJ7E"
      },
      "outputs": [],
      "source": [
        "# Инициализация кастомной модели\n",
        "custom_segmentation_model = PyramidUNetCore(categories_out=number_of_classes).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1gPrxP4QJ7E",
        "outputId": "73fa484a-cc83-42ff-e404-1fa86b494016"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 01| taining loss: 1.9355  | val loss: 1.7563 | iou: 0.5320 | f1: 0.6945\n",
            "epoch 02| taining loss: 1.7153  | val loss: 1.7475 | iou: 0.5305 | f1: 0.6932\n",
            "epoch 03| taining loss: 1.6697  | val loss: 1.7488 | iou: 0.4692 | f1: 0.6388\n",
            "epoch 04| taining loss: 1.6379  | val loss: 1.6947 | iou: 0.4755 | f1: 0.6445\n",
            "epoch 05| taining loss: 1.6744  | val loss: 1.6943 | iou: 0.5034 | f1: 0.6697\n",
            "epoch 06| taining loss: 1.6286  | val loss: 1.7395 | iou: 0.5091 | f1: 0.6747\n",
            "epoch 07| taining loss: 1.6194  | val loss: 1.7074 | iou: 0.5084 | f1: 0.6741\n",
            "epoch 08| taining loss: 1.5995  | val loss: 1.7479 | iou: 0.4743 | f1: 0.6434\n",
            "epoch 09| taining loss: 1.6318  | val loss: 1.6541 | iou: 0.4886 | f1: 0.6564\n",
            "epoch 10| taining loss: 1.5756  | val loss: 1.6408 | iou: 0.5133 | f1: 0.6784\n",
            "epoch 11| taining loss: 1.6012  | val loss: 1.6047 | iou: 0.5316 | f1: 0.6942\n",
            "epoch 12| taining loss: 1.5489  | val loss: 1.5223 | iou: 0.5483 | f1: 0.7083\n",
            "epoch 13| taining loss: 1.5680  | val loss: 1.6084 | iou: 0.5160 | f1: 0.6808\n",
            "epoch 14| taining loss: 1.5653  | val loss: 1.6142 | iou: 0.4841 | f1: 0.6524\n",
            "epoch 15| taining loss: 1.5600  | val loss: 1.5669 | iou: 0.5424 | f1: 0.7033\n",
            "epoch 16| taining loss: 1.5484  | val loss: 1.5836 | iou: 0.5238 | f1: 0.6875\n",
            "epoch 17| taining loss: 1.5220  | val loss: 1.4636 | iou: 0.5487 | f1: 0.7086\n",
            "epoch 18| taining loss: 1.5582  | val loss: 1.5496 | iou: 0.5287 | f1: 0.6917\n",
            "epoch 19| taining loss: 1.4874  | val loss: 1.5164 | iou: 0.5241 | f1: 0.6878\n",
            "epoch 20| taining loss: 1.5247  | val loss: 1.6022 | iou: 0.5071 | f1: 0.6729\n",
            "epoch 21| taining loss: 1.4918  | val loss: 1.6295 | iou: 0.4615 | f1: 0.6316\n",
            "epoch 22| taining loss: 1.5247  | val loss: 1.6037 | iou: 0.4733 | f1: 0.6425\n",
            "epoch 23| taining loss: 1.4638  | val loss: 1.5517 | iou: 0.5037 | f1: 0.6700\n",
            "epoch 24| taining loss: 1.5044  | val loss: 1.5610 | iou: 0.4807 | f1: 0.6493\n",
            "epoch 25| taining loss: 1.4813  | val loss: 1.4873 | iou: 0.5259 | f1: 0.6893\n",
            "epoch 26| taining loss: 1.4604  | val loss: 1.3738 | iou: 0.5674 | f1: 0.7240\n",
            "epoch 27| taining loss: 1.5426  | val loss: 1.8382 | iou: 0.2787 | f1: 0.4359\n",
            "epoch 28| taining loss: 1.5591  | val loss: 1.4801 | iou: 0.5453 | f1: 0.7058\n",
            "epoch 29| taining loss: 1.5461  | val loss: 1.6087 | iou: 0.4619 | f1: 0.6319\n",
            "epoch 30| taining loss: 1.5415  | val loss: 1.7673 | iou: 0.3050 | f1: 0.4675\n"
          ]
        }
      ],
      "source": [
        "custom_model_epochs = 30\n",
        "custom_model_lr = 1e-3\n",
        "\n",
        "execute_custom_training(\n",
        "    core_network=custom_segmentation_model,\n",
        "    data_train=refined_batcher,\n",
        "    data_val=val_batcher,\n",
        "    epoch_limit=custom_model_epochs,\n",
        "    initial_lr=custom_model_lr\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ePXlFqZQJ7F"
      },
      "source": [
        "f1=0.4675 - это почти в половину хуже чем библиотечная модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCwomeEvQJ7F",
        "outputId": "49745e24-1b76-4965-dc23-0af873e3f468"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "vision_transformer_model = HybridVisionEncoder(\n",
        "    resolution=224,\n",
        "    token_size=32,\n",
        "    channels_in=3,\n",
        "    embed_channels=128,\n",
        "    heads=4,\n",
        "    layers=2,\n",
        "    class_count=number_of_classes\n",
        ").to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWC0VEt_QJ7F"
      },
      "source": [
        "Обучим трансформер:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UA63RdkWQJ7G",
        "outputId": "dac1be34-f207-4c4a-ba12-3cc021947d0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 01| taining loss: 1.9870  | val loss: 1.6861 | iou: 0.5320 | f1: 0.6945\n",
            "epoch 02| taining loss: 1.7048  | val loss: 1.7761 | iou: 0.4637 | f1: 0.6336\n",
            "epoch 03| taining loss: 1.6772  | val loss: 1.7166 | iou: 0.4058 | f1: 0.5774\n",
            "epoch 04| taining loss: 1.6272  | val loss: 1.6915 | iou: 0.3749 | f1: 0.5453\n",
            "epoch 05| taining loss: 1.6164  | val loss: 1.6079 | iou: 0.5268 | f1: 0.6901\n",
            "epoch 06| taining loss: 1.5431  | val loss: 1.5762 | iou: 0.5215 | f1: 0.6855\n",
            "epoch 07| taining loss: 1.5761  | val loss: 1.6801 | iou: 0.4795 | f1: 0.6482\n",
            "epoch 08| taining loss: 1.6004  | val loss: 1.5815 | iou: 0.5245 | f1: 0.6881\n",
            "epoch 09| taining loss: 1.5384  | val loss: 1.6503 | iou: 0.4444 | f1: 0.6153\n",
            "epoch 10| taining loss: 1.5351  | val loss: 1.7854 | iou: 0.4105 | f1: 0.5821\n",
            "epoch 11| taining loss: 1.4905  | val loss: 1.6591 | iou: 0.4363 | f1: 0.6075\n",
            "epoch 12| taining loss: 1.5027  | val loss: 1.6759 | iou: 0.4091 | f1: 0.5806\n",
            "epoch 13| taining loss: 1.5329  | val loss: 1.7227 | iou: 0.3851 | f1: 0.5560\n",
            "epoch 14| taining loss: 1.4937  | val loss: 1.7062 | iou: 0.3755 | f1: 0.5459\n",
            "epoch 15| taining loss: 1.5082  | val loss: 1.6015 | iou: 0.4509 | f1: 0.6216\n",
            "epoch 16| taining loss: 1.5013  | val loss: 1.6770 | iou: 0.4070 | f1: 0.5786\n",
            "epoch 17| taining loss: 1.4494  | val loss: 1.6903 | iou: 0.3978 | f1: 0.5692\n",
            "epoch 18| taining loss: 1.4741  | val loss: 1.6375 | iou: 0.3576 | f1: 0.5268\n",
            "epoch 19| taining loss: 1.4766  | val loss: 1.6829 | iou: 0.4440 | f1: 0.6150\n",
            "epoch 20| taining loss: 1.4569  | val loss: 1.6284 | iou: 0.4083 | f1: 0.5799\n",
            "epoch 21| taining loss: 1.4976  | val loss: 1.5891 | iou: 0.4279 | f1: 0.5994\n",
            "epoch 22| taining loss: 1.4865  | val loss: 1.6909 | iou: 0.4258 | f1: 0.5973\n",
            "epoch 23| taining loss: 1.4264  | val loss: 1.5940 | iou: 0.4093 | f1: 0.5808\n",
            "epoch 24| taining loss: 1.4126  | val loss: 1.6295 | iou: 0.4228 | f1: 0.5944\n",
            "epoch 25| taining loss: 1.4463  | val loss: 1.6316 | iou: 0.3614 | f1: 0.5310\n",
            "epoch 26| taining loss: 1.4676  | val loss: 1.6207 | iou: 0.4188 | f1: 0.5904\n",
            "epoch 27| taining loss: 1.4236  | val loss: 1.6720 | iou: 0.3821 | f1: 0.5529\n",
            "epoch 28| taining loss: 1.4338  | val loss: 1.6207 | iou: 0.4607 | f1: 0.6307\n",
            "epoch 29| taining loss: 1.4797  | val loss: 1.6975 | iou: 0.3577 | f1: 0.5270\n",
            "epoch 30| taining loss: 1.4537  | val loss: 1.6690 | iou: 0.3987 | f1: 0.5701\n"
          ]
        }
      ],
      "source": [
        "vit_epochs = 30\n",
        "vit_learning_rate = 1e-3\n",
        "\n",
        "execute_custom_training(\n",
        "    core_network=vision_transformer_model,\n",
        "    data_train=refined_batcher,\n",
        "    data_val=val_batcher,\n",
        "    epoch_limit=vit_epochs,\n",
        "    initial_lr=vit_learning_rate\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3VO2clNQJ7G"
      },
      "source": [
        "Получил f1=0.5701 это лучше чем предыдущая сборка, но всё равно не достигает качества библиотечной модели. Перейдем к улучшению бейзлайна"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "-wJIluYDQJ7G"
      },
      "outputs": [],
      "source": [
        "# Настройка оптимизаторов и scheduler-ов\n",
        "cnn_optimizer = optim.AdamW(custom_segmentation_model.parameters(), lr=1e-4)\n",
        "cnn_scheduler = CosineAnnealingLR(cnn_optimizer, T_max=10)\n",
        "\n",
        "vit_optimizer = optim.AdamW(vision_transformer_model.parameters(), lr=1e-4)\n",
        "vit_scheduler = CosineAnnealingLR(vit_optimizer, T_max=10)\n",
        "\n",
        "# Loss\n",
        "combined_dice_loss = smp.losses.DiceLoss(mode=\"multiclass\")\n",
        "combined_ce_loss = nn.CrossEntropyLoss()\n",
        "\n",
        "# Улучшённый цикл обучения с scheduler\n",
        "def run_improved_training(core_model, optimizer_engine, scheduler_engine, train_data, val_data, total_epochs=30):\n",
        "    for epoch_counter in range(1, total_epochs + 1):\n",
        "        core_model.train()\n",
        "        epoch_loss_sum = 0.0\n",
        "\n",
        "        loop_bar = tqdm(train_data, desc=f\"Epoch {epoch_counter}/{total_epochs} - Improved Train\", leave=False)\n",
        "\n",
        "        for input_data, ground_truth in loop_bar:\n",
        "            input_data = input_data.to(device)\n",
        "            ground_truth = ground_truth.to(device)\n",
        "\n",
        "            optimizer_engine.zero_grad()\n",
        "            output_logits = core_model(input_data)\n",
        "            batch_loss = combined_dice_loss(output_logits, ground_truth) + combined_ce_loss(output_logits, ground_truth)\n",
        "            batch_loss.backward()\n",
        "            optimizer_engine.step()\n",
        "\n",
        "            epoch_loss_sum += batch_loss.item()\n",
        "\n",
        "        scheduler_engine.step()\n",
        "        validation_outcomes = assess_model_performance(core_model, val_data, categories=number_of_classes)\n",
        "        average_loss = epoch_loss_sum / len(train_data)\n",
        "\n",
        "        print(f\"[{epoch_counter:02d}/{total_epochs}] \"\n",
        "              f\"Train Loss: {average_loss:.5f} | \"\n",
        "              f\"Val Loss: {validation_outcomes['loss']:.5f} | \"\n",
        "              f\"IoU: {validation_outcomes['iou']:.5f} | \"\n",
        "              f\"F1: {validation_outcomes['f1']:.5f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVSAW5deQJ7G"
      },
      "source": [
        "Обучим CNN модель:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viBbijBLQJ7G",
        "outputId": "6df5a3fe-47db-418e-bdfb-b67fc971edc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 01| tr loss: 1.5552  | val loss: 1.5999 | iou: 0.4347 | f1: 0.6060\n",
            "epoch 02| tr loss: 1.4538  | val loss: 1.5136 | iou: 0.5018 | f1: 0.6683\n",
            "epoch 03| tr loss: 1.4502  | val loss: 1.4880 | iou: 0.5119 | f1: 0.6771\n",
            "epoch 04| tr loss: 1.4189  | val loss: 1.5031 | iou: 0.4859 | f1: 0.6540\n",
            "epoch 05| tr loss: 1.4478  | val loss: 1.5111 | iou: 0.4672 | f1: 0.6369\n",
            "epoch 06| tr loss: 1.5082  | val loss: 1.5055 | iou: 0.4673 | f1: 0.6370\n",
            "epoch 07| tr loss: 1.4142  | val loss: 1.4992 | iou: 0.4727 | f1: 0.6419\n",
            "epoch 08| tr loss: 1.4659  | val loss: 1.4974 | iou: 0.4744 | f1: 0.6436\n",
            "epoch 09| tr loss: 1.4305  | val loss: 1.4965 | iou: 0.4746 | f1: 0.6437\n",
            "epoch 10| tr loss: 1.4175  | val loss: 1.4952 | iou: 0.4752 | f1: 0.6442\n",
            "epoch 11| tr loss: 1.4606  | val loss: 1.4952 | iou: 0.4752 | f1: 0.6442\n",
            "epoch 12| tr loss: 1.4322  | val loss: 1.4945 | iou: 0.4755 | f1: 0.6445\n",
            "epoch 13| tr loss: 1.4426  | val loss: 1.4914 | iou: 0.4766 | f1: 0.6456\n",
            "epoch 14| tr loss: 1.4027  | val loss: 1.4840 | iou: 0.4797 | f1: 0.6484\n",
            "epoch 15| tr loss: 1.4550  | val loss: 1.4763 | iou: 0.4839 | f1: 0.6522\n",
            "epoch 16| tr loss: 1.3996  | val loss: 1.4907 | iou: 0.4730 | f1: 0.6422\n",
            "epoch 17| tr loss: 1.3810  | val loss: 1.4556 | iou: 0.4887 | f1: 0.6565\n",
            "epoch 18| tr loss: 1.4446  | val loss: 1.4926 | iou: 0.4708 | f1: 0.6402\n",
            "epoch 19| tr loss: 1.4148  | val loss: 1.4212 | iou: 0.5099 | f1: 0.6754\n",
            "epoch 20| tr loss: 1.4101  | val loss: 1.4135 | iou: 0.5075 | f1: 0.6733\n",
            "epoch 21| tr loss: 1.3875  | val loss: 1.3884 | iou: 0.5128 | f1: 0.6780\n",
            "epoch 22| tr loss: 1.4028  | val loss: 1.3869 | iou: 0.5203 | f1: 0.6844\n",
            "epoch 23| tr loss: 1.4449  | val loss: 1.4495 | iou: 0.4979 | f1: 0.6648\n",
            "epoch 24| tr loss: 1.3262  | val loss: 1.4320 | iou: 0.5032 | f1: 0.6695\n",
            "epoch 25| tr loss: 1.3869  | val loss: 1.4181 | iou: 0.5186 | f1: 0.6830\n",
            "epoch 26| tr loss: 1.3406  | val loss: 1.4029 | iou: 0.5273 | f1: 0.6905\n",
            "epoch 27| tr loss: 1.3518  | val loss: 1.4435 | iou: 0.5119 | f1: 0.6772\n",
            "epoch 28| tr loss: 1.3526  | val loss: 1.4054 | iou: 0.5262 | f1: 0.6895\n",
            "epoch 29| tr loss: 1.3182  | val loss: 1.4019 | iou: 0.5271 | f1: 0.6903\n",
            "epoch 30| tr loss: 1.3792  | val loss: 1.4043 | iou: 0.5261 | f1: 0.6894\n"
          ]
        }
      ],
      "source": [
        "cnn_improved_epochs = 30\n",
        "\n",
        "run_improved_training(\n",
        "    core_model=custom_segmentation_model,\n",
        "    optimizer_engine=cnn_optimizer,\n",
        "    scheduler_engine=cnn_scheduler,\n",
        "    train_data=refined_batcher,\n",
        "    val_data=val_batcher,\n",
        "    total_epochs=cnn_improved_epochs\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNQmN-tKQJ7H"
      },
      "source": [
        "В результате обучения кастомной модели удалось достичь значения F1-score = 0.6894, что немного превышает показатели базовой версии. Это показывает, что применённые методы улучшения смогли повысить качество модели. Далее переходим к обучению трансформерной архитектуры.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uocFA1-QJ7H",
        "outputId": "342d3aa0-b6eb-472e-9ec5-9223183eb0f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 01| tr loss: 1.3883  | val loss: 1.6667 | iou: 0.3953 | f1: 0.5666\n",
            "epoch 02| tr loss: 1.3923  | val loss: 1.6609 | iou: 0.3990 | f1: 0.5704\n",
            "epoch 03| tr loss: 1.3709  | val loss: 1.6594 | iou: 0.3964 | f1: 0.5678\n",
            "epoch 04| tr loss: 1.3280  | val loss: 1.6762 | iou: 0.3898 | f1: 0.5609\n",
            "epoch 05| tr loss: 1.3141  | val loss: 1.6813 | iou: 0.3879 | f1: 0.5590\n",
            "epoch 06| tr loss: 1.3477  | val loss: 1.6769 | iou: 0.3917 | f1: 0.5630\n",
            "epoch 07| tr loss: 1.3448  | val loss: 1.6716 | iou: 0.3958 | f1: 0.5671\n",
            "epoch 08| tr loss: 1.3053  | val loss: 1.6697 | iou: 0.3967 | f1: 0.5681\n",
            "epoch 09| tr loss: 1.3626  | val loss: 1.6681 | iou: 0.3970 | f1: 0.5683\n",
            "epoch 10| tr loss: 1.3401  | val loss: 1.6683 | iou: 0.3971 | f1: 0.5684\n",
            "epoch 11| tr loss: 1.2690  | val loss: 1.6683 | iou: 0.3971 | f1: 0.5684\n",
            "epoch 12| tr loss: 1.3446  | val loss: 1.6682 | iou: 0.3970 | f1: 0.5684\n",
            "epoch 13| tr loss: 1.3138  | val loss: 1.6684 | iou: 0.3968 | f1: 0.5681\n",
            "epoch 14| tr loss: 1.3281  | val loss: 1.6671 | iou: 0.3965 | f1: 0.5678\n",
            "epoch 15| tr loss: 1.3288  | val loss: 1.6677 | iou: 0.3943 | f1: 0.5656\n",
            "epoch 16| tr loss: 1.3065  | val loss: 1.6814 | iou: 0.3959 | f1: 0.5672\n",
            "epoch 17| tr loss: 1.2785  | val loss: 1.6834 | iou: 0.3908 | f1: 0.5620\n",
            "epoch 18| tr loss: 1.3047  | val loss: 1.6712 | iou: 0.3950 | f1: 0.5663\n",
            "epoch 19| tr loss: 1.3152  | val loss: 1.6745 | iou: 0.3954 | f1: 0.5668\n",
            "epoch 20| tr loss: 1.3470  | val loss: 1.6885 | iou: 0.3965 | f1: 0.5679\n",
            "epoch 21| tr loss: 1.3976  | val loss: 1.6995 | iou: 0.3987 | f1: 0.5701\n",
            "epoch 22| tr loss: 1.3334  | val loss: 1.6934 | iou: 0.3980 | f1: 0.5694\n",
            "epoch 23| tr loss: 1.3489  | val loss: 1.6802 | iou: 0.3977 | f1: 0.5690\n",
            "epoch 24| tr loss: 1.3515  | val loss: 1.6776 | iou: 0.3998 | f1: 0.5712\n",
            "epoch 25| tr loss: 1.2864  | val loss: 1.6789 | iou: 0.4021 | f1: 0.5736\n",
            "epoch 26| tr loss: 1.2675  | val loss: 1.6776 | iou: 0.4047 | f1: 0.5762\n",
            "epoch 27| tr loss: 1.3225  | val loss: 1.6783 | iou: 0.4054 | f1: 0.5769\n",
            "epoch 28| tr loss: 1.2977  | val loss: 1.6750 | iou: 0.4044 | f1: 0.5759\n",
            "epoch 29| tr loss: 1.3245  | val loss: 1.6743 | iou: 0.4034 | f1: 0.5749\n",
            "epoch 30| tr loss: 1.3073  | val loss: 1.6744 | iou: 0.4032 | f1: 0.5747\n"
          ]
        }
      ],
      "source": [
        "vit_improved_epochs = 30\n",
        "\n",
        "run_improved_training(\n",
        "    core_model=vision_transformer_model,\n",
        "    optimizer_engine=vit_optimizer,\n",
        "    scheduler_engine=vit_scheduler,\n",
        "    train_data=refined_batcher,\n",
        "    val_data=val_batcher,\n",
        "    total_epochs=vit_improved_epochs\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycNQg7RRQJ7H"
      },
      "source": [
        "f1=0.5747 - это значит, что гипотеза все-таки неудачна и не позволяет универсально улучшить качество моделей, трансформер также имеет худший показатель"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "04bd65b7ec2747c8965a9ef6942a6fb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_73bea592279d4085a73fbb66157d20fb",
              "IPY_MODEL_55afc53bcb5e4538b41e88b8e3894626",
              "IPY_MODEL_38f08ecefd6f4457bbf4849fd2b5d932"
            ],
            "layout": "IPY_MODEL_3361aec9b57f479292d5c076a58da839"
          }
        },
        "73bea592279d4085a73fbb66157d20fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffde8306dcfb4f0d89a3917874127137",
            "placeholder": "​",
            "style": "IPY_MODEL_62f0840ca12a46249ccbf6772661a3fa",
            "value": "config.json: 100%"
          }
        },
        "55afc53bcb5e4538b41e88b8e3894626": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5ef3d89b3c840e6806bfd794ba47cd5",
            "max": 156,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c62f9ce60861456bb0a3a9505ed9a0e2",
            "value": 156
          }
        },
        "38f08ecefd6f4457bbf4849fd2b5d932": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b93ec0bde594430383d10248514e350f",
            "placeholder": "​",
            "style": "IPY_MODEL_bd46baaf36a04053ae740956f33d0a40",
            "value": " 156/156 [00:00&lt;00:00, 11.1kB/s]"
          }
        },
        "3361aec9b57f479292d5c076a58da839": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffde8306dcfb4f0d89a3917874127137": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62f0840ca12a46249ccbf6772661a3fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b5ef3d89b3c840e6806bfd794ba47cd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c62f9ce60861456bb0a3a9505ed9a0e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b93ec0bde594430383d10248514e350f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd46baaf36a04053ae740956f33d0a40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e98629eb9f164a6f99370ba570ea4d6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d369af2f710b46dcaceb28fc80420e6b",
              "IPY_MODEL_082e7f1957b246deaa2363fd54f23295",
              "IPY_MODEL_95a16eccd0b642c1b5b51de674b6254c"
            ],
            "layout": "IPY_MODEL_46432e6daf7746b88f56efa1eb1f109a"
          }
        },
        "d369af2f710b46dcaceb28fc80420e6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1984e313ab6046719ae2a080d8b30d77",
            "placeholder": "​",
            "style": "IPY_MODEL_f56fa29a277949738f9304926e07ccd9",
            "value": "model.safetensors: 100%"
          }
        },
        "082e7f1957b246deaa2363fd54f23295": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d76c714f360641a0b4cbc5c74946c22a",
            "max": 87275112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_33db9b6887684cdd96af2ad362834e35",
            "value": 87275112
          }
        },
        "95a16eccd0b642c1b5b51de674b6254c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1923246178a0482cadd7ab3785032843",
            "placeholder": "​",
            "style": "IPY_MODEL_d6f035dd61754a549dcde0f0a3fa3884",
            "value": " 87.3M/87.3M [00:00&lt;00:00, 163MB/s]"
          }
        },
        "46432e6daf7746b88f56efa1eb1f109a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1984e313ab6046719ae2a080d8b30d77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f56fa29a277949738f9304926e07ccd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d76c714f360641a0b4cbc5c74946c22a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33db9b6887684cdd96af2ad362834e35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1923246178a0482cadd7ab3785032843": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6f035dd61754a549dcde0f0a3fa3884": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad6f90a42c434f46a85215e8239cbe54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_56cf6c31ae434473855d69ce2107e95e",
              "IPY_MODEL_573c03adfac740a8abcf61ab3a7f15f6",
              "IPY_MODEL_ebc288621bfd404985e208512c7fda4a"
            ],
            "layout": "IPY_MODEL_a612c2bc09964c33b16e949959820c0e"
          }
        },
        "56cf6c31ae434473855d69ce2107e95e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e966d6c1b1d485e9645d74b6472a6d1",
            "placeholder": "​",
            "style": "IPY_MODEL_d3f4b29f0bff4ddb99da6bb303af7c69",
            "value": "config.json: 100%"
          }
        },
        "573c03adfac740a8abcf61ab3a7f15f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d3b9818309149c99477fc6b26cb4563",
            "max": 135,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3be53c23ea9a4e299b9348f141e5846b",
            "value": 135
          }
        },
        "ebc288621bfd404985e208512c7fda4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a645f01abe147a595e4abe2e71817d5",
            "placeholder": "​",
            "style": "IPY_MODEL_a49a8ebfbbb44075bf3ec49ed32e405c",
            "value": " 135/135 [00:00&lt;00:00, 14.3kB/s]"
          }
        },
        "a612c2bc09964c33b16e949959820c0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e966d6c1b1d485e9645d74b6472a6d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3f4b29f0bff4ddb99da6bb303af7c69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d3b9818309149c99477fc6b26cb4563": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3be53c23ea9a4e299b9348f141e5846b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2a645f01abe147a595e4abe2e71817d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a49a8ebfbbb44075bf3ec49ed32e405c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a46b14dc783f4661aab41ed77d477d60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7d25f7159b0544c393fb898122b6d57b",
              "IPY_MODEL_34175474908f460ca23c67f6e6087d11",
              "IPY_MODEL_0b62eb5b07e14634bf18701950e61b5e"
            ],
            "layout": "IPY_MODEL_126843c63cfb48dc9016a7568000ee06"
          }
        },
        "7d25f7159b0544c393fb898122b6d57b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed8a7bf35ee1441eb262d5d447b178fd",
            "placeholder": "​",
            "style": "IPY_MODEL_e740273f7061443491607258da6b1f21",
            "value": "model.safetensors: 100%"
          }
        },
        "34175474908f460ca23c67f6e6087d11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39f5f8c0f3f74212bc3748b089b15261",
            "max": 14321416,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8fd9d45701ba49eabcd69bdb5e415ae4",
            "value": 14321416
          }
        },
        "0b62eb5b07e14634bf18701950e61b5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab07348ee3dc4540af5724f4df86e6e6",
            "placeholder": "​",
            "style": "IPY_MODEL_4931c869baa547f7905cf0c152f9f9a9",
            "value": " 14.3M/14.3M [00:00&lt;00:00, 230MB/s]"
          }
        },
        "126843c63cfb48dc9016a7568000ee06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed8a7bf35ee1441eb262d5d447b178fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e740273f7061443491607258da6b1f21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39f5f8c0f3f74212bc3748b089b15261": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fd9d45701ba49eabcd69bdb5e415ae4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ab07348ee3dc4540af5724f4df86e6e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4931c869baa547f7905cf0c152f9f9a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e2d92004905743fd8fbe251f84fb4d59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5b1ce771bb1846e7a2db7726b7597f12",
              "IPY_MODEL_8faba61d6c95488e8926ac701ecb0a39",
              "IPY_MODEL_20442f1f5c7347c49a2f0a3b959f1e5d"
            ],
            "layout": "IPY_MODEL_132047ff9df64bce8ce349a164485aea"
          }
        },
        "5b1ce771bb1846e7a2db7726b7597f12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80fb797847764f5ea50db2b38d310bab",
            "placeholder": "​",
            "style": "IPY_MODEL_d95da25a68e647a89b979889efb26f41",
            "value": "config.json: 100%"
          }
        },
        "8faba61d6c95488e8926ac701ecb0a39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7ad8bf84b9e451baedb9121b4b4b263",
            "max": 156,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7f64ab819d724f5cbbf53efb2591a41d",
            "value": 156
          }
        },
        "20442f1f5c7347c49a2f0a3b959f1e5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c50f0ba73c94529841823f21fa2b0db",
            "placeholder": "​",
            "style": "IPY_MODEL_505a023a0a8a44db970c447af93fb37e",
            "value": " 156/156 [00:00&lt;00:00, 9.21kB/s]"
          }
        },
        "132047ff9df64bce8ce349a164485aea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80fb797847764f5ea50db2b38d310bab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d95da25a68e647a89b979889efb26f41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7ad8bf84b9e451baedb9121b4b4b263": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f64ab819d724f5cbbf53efb2591a41d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8c50f0ba73c94529841823f21fa2b0db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "505a023a0a8a44db970c447af93fb37e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba6aaa44bd7449a7829f6a5fd97e9a34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2b9d1578fc3e46abb2ff569a3cc60e54",
              "IPY_MODEL_5fc213eb3b314423927013f830747731",
              "IPY_MODEL_0cdae9b0fc7b46d49196bf2e696d8d14"
            ],
            "layout": "IPY_MODEL_29c4d15ecca145edb7467fa56fce89ba"
          }
        },
        "2b9d1578fc3e46abb2ff569a3cc60e54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_781aeff7492b4898abfa86aa3f1175a8",
            "placeholder": "​",
            "style": "IPY_MODEL_30fbdd334ed643d0a96dbad1168a2927",
            "value": "model.safetensors: 100%"
          }
        },
        "5fc213eb3b314423927013f830747731": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ec3f0015aa34b468f7d9e44a8cf2244",
            "max": 102464800,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_89cb8773f9d3413eb80f45d40d6efc9a",
            "value": 102464800
          }
        },
        "0cdae9b0fc7b46d49196bf2e696d8d14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f76d09145504ec4a44ade6d0c62248c",
            "placeholder": "​",
            "style": "IPY_MODEL_cdd66c7cf76740a1a4d6b3da0706abec",
            "value": " 102M/102M [00:00&lt;00:00, 196MB/s]"
          }
        },
        "29c4d15ecca145edb7467fa56fce89ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "781aeff7492b4898abfa86aa3f1175a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30fbdd334ed643d0a96dbad1168a2927": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ec3f0015aa34b468f7d9e44a8cf2244": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89cb8773f9d3413eb80f45d40d6efc9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4f76d09145504ec4a44ade6d0c62248c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdd66c7cf76740a1a4d6b3da0706abec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
